{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import run_nerf\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args:\n",
      "expname = blender_test_simplest\n",
      "basedir = ./logs\n",
      "datadir = ./data/blender_test_simplest\n",
      "dataset_type = blender\n",
      "\n",
      "half_res = True\n",
      "no_batching = True\n",
      "\n",
      "N_samples = 64\n",
      "N_importance = 64\n",
      "\n",
      "use_viewdirs = True\n",
      "white_bkgd = True\n",
      "N_rand = 1024\n",
      "loaded args\n"
     ]
    }
   ],
   "source": [
    "basedir = \"C:\\\\projects\\\\rendering\\\\nerf\\\\logs\"\n",
    "\n",
    "expname = 'blender_test_simplest'\n",
    "\n",
    "config = os.path.join(basedir, expname, 'config.txt')\n",
    "print('Args:')\n",
    "print(open(config, 'r').read())\n",
    "parser = run_nerf.config_parser()\n",
    "\n",
    "args = parser.parse_args('--config {} --ft_path {}'.format(config, os.path.join(basedir, expname, 'model_008000.npy')))\n",
    "print('loaded args')\n",
    "\n",
    "images, poses, render_poses, hwf, i_split = load_blender_data(\n",
    "    args.datadir, args.half_res, args.testskip)\n",
    "H, W, focal = poses[0,:3,-1].astype(np.float32)\n",
    "\n",
    "H = int(H)\n",
    "W = int(W)\n",
    "hwf = [H, W, focal]\n",
    "\n",
    "images = images.astype(np.float32)\n",
    "poses = poses.astype(np.float32)\n",
    "\n",
    "if args.no_ndc:\n",
    "    near = tf.reduce_min(bds) * .9\n",
    "    far = tf.reduce_max(bds) * 1.\n",
    "else:\n",
    "    near = 0.\n",
    "    far = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 63 27 <class 'int'> <class 'int'> True\n",
      "(None, 90) (None, 63) (None, 27)\n",
      "MODEL 63 27 <class 'int'> <class 'int'> True\n",
      "(None, 90) (None, 63) (None, 27)\n",
      "Not ndc!\n",
      "Found ckpts ['C:\\\\projects\\\\rendering\\\\nerf\\\\logs\\\\blender_test_simplest\\\\model_008000.npy']\n",
      "Reloading from C:\\projects\\rendering\\nerf\\logs\\blender_test_simplest\\model_008000.npy\n",
      "Resetting step to 8001\n",
      "Reloading fine from C:\\projects\\rendering\\nerf\\logs\\blender_test_simplest\\model_fine_008000.npy\n",
      "Render kwargs:\n",
      "{'N_importance': 64,\n",
      " 'N_samples': 64,\n",
      " 'far': <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
      " 'lindisp': False,\n",
      " 'ndc': False,\n",
      " 'near': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
      " 'network_fine': <keras.engine.functional.Functional object at 0x000001909BE72BF0>,\n",
      " 'network_fn': <keras.engine.functional.Functional object at 0x000001909BFE9450>,\n",
      " 'network_query_fn': <function create_nerf.<locals>.network_query_fn at 0x000001909BFA9FC0>,\n",
      " 'perturb': False,\n",
      " 'raw_noise_std': 0.0,\n",
      " 'use_viewdirs': True,\n",
      " 'white_bkgd': True}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rgb_map'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [5], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m render_kwargs_fast[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN_importance\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     18\u001B[0m c2w \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39meye(\u001B[38;5;241m4\u001B[39m)[:\u001B[38;5;241m3\u001B[39m,:\u001B[38;5;241m4\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32) \u001B[38;5;66;03m# identity pose matrix\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m test \u001B[38;5;241m=\u001B[39m run_nerf\u001B[38;5;241m.\u001B[39mrender(H\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mdown, W\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mdown, focal\u001B[38;5;241m/\u001B[39mdown, c2w\u001B[38;5;241m=\u001B[39mc2w, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrender_kwargs_fast)\n\u001B[0;32m     20\u001B[0m img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(test[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     21\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(img)\n",
      "File \u001B[1;32mC:\\projects\\rendering\\nerf\\run_nerf.py:331\u001B[0m, in \u001B[0;36mrender\u001B[1;34m(H, W, focal, chunk, rays, c2w, ndc, near, far, use_viewdirs, c2w_staticcam, **kwargs)\u001B[0m\n\u001B[0;32m    328\u001B[0m     all_ret[k] \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(all_ret[k], k_sh)\n\u001B[0;32m    330\u001B[0m k_extract \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb_map\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisp_map\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc_map\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 331\u001B[0m ret_list \u001B[38;5;241m=\u001B[39m [all_ret[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m k_extract]\n\u001B[0;32m    332\u001B[0m ret_dict \u001B[38;5;241m=\u001B[39m {k: all_ret[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m all_ret \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m k_extract}\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret_list \u001B[38;5;241m+\u001B[39m [ret_dict]\n",
      "File \u001B[1;32mC:\\projects\\rendering\\nerf\\run_nerf.py:331\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    328\u001B[0m     all_ret[k] \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(all_ret[k], k_sh)\n\u001B[0;32m    330\u001B[0m k_extract \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb_map\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisp_map\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc_map\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 331\u001B[0m ret_list \u001B[38;5;241m=\u001B[39m [\u001B[43mall_ret\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m k_extract]\n\u001B[0;32m    332\u001B[0m ret_dict \u001B[38;5;241m=\u001B[39m {k: all_ret[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m all_ret \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m k_extract}\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret_list \u001B[38;5;241m+\u001B[39m [ret_dict]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'rgb_map'"
     ]
    }
   ],
   "source": [
    "# Create nerf model\n",
    "_, render_kwargs_test, start, grad_vars, models = run_nerf.create_nerf(args)\n",
    "\n",
    "bds_dict = {\n",
    "    'near' : tf.cast(near, tf.float32),\n",
    "    'far' : tf.cast(far, tf.float32),\n",
    "}\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "print('Render kwargs:')\n",
    "pprint.pprint(render_kwargs_test)\n",
    "\n",
    "\n",
    "down = 4\n",
    "render_kwargs_fast = {k : render_kwargs_test[k] for k in render_kwargs_test}\n",
    "render_kwargs_fast['N_importance'] = 0\n",
    "\n",
    "c2w = np.eye(4)[:3,:4].astype(np.float32) # identity pose matrix\n",
    "test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "img = np.clip(test[0],0,1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = 8 # trade off resolution+aliasing for render speed to make this video faster\n",
    "frames = []\n",
    "for i, c2w in enumerate(render_poses):\n",
    "    if i%8==0: print(i)\n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w[:3,:4], **render_kwargs_fast)\n",
    "    frames.append((255*np.clip(test[0],0,1)).astype(np.uint8))\n",
    "    \n",
    "print('done, saving')\n",
    "f = 'logs/fern_example/video.mp4'\n",
    "imageio.mimwrite(f, frames, fps=30, quality=8)\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(f, height=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433cdb87f14e4a738c3b1d502431b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x', max=1.0, min=-1.0, step=0.01), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def f(x, y, z):\n",
    "    \n",
    "    c2w = tf.convert_to_tensor([\n",
    "        [1,0,0,x],\n",
    "        [0,1,0,y],\n",
    "        [0,0,1,z],\n",
    "        [0,0,0,1],\n",
    "    ], dtype=tf.float32)\n",
    "    \n",
    "    test = run_nerf.render(H//down, W//down, focal/down, c2w=c2w, **render_kwargs_fast)\n",
    "    img = np.clip(test[0],0,1)\n",
    "    \n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sldr = lambda : widgets.FloatSlider(\n",
    "    value=0.,\n",
    "    min=-1.,\n",
    "    max=1.,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = ['x', 'y', 'z']\n",
    "    \n",
    "interactive_plot = interactive(f, **{n : sldr() for n in names})\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}